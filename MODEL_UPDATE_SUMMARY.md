# λ¨λΈ μ—…λ°μ΄νΈ μ”μ•½

## λ³€κ²½ μ‚¬ν•­

### π”„ νμΈνλ‹ λ¨λΈ κµμ²΄
- **κΈ°μ΅΄**: `beomi/KoAlpaca-Polyglot-5.8B` + LoRA μ–΄λ‘ν„° (`./models/koalpaca-bang-model`)
- **λ³€κ²½**: `minjeongHuggingFace/koalpaca-bang_e9` (ν—κΉ…νμ΄μ¤μ—μ„ μ§μ ‘ λ΅λ“)

### π“ μμ •λ νμΌλ“¤

#### 1. `services/finetuning_service.py`
- **μ£Όμ” λ³€κ²½μ‚¬ν•­**:
  - ν—κΉ…νμ΄μ¤ λ¨λΈ `minjeongHuggingFace/koalpaca-bang_e9` μ§μ ‘ λ΅λ“
  - LoRA/PEFT λ΅μ§ μ κ±° (μ™„μ „ νμΈνλ‹λ λ¨λΈμ΄λ―€λ΅)
  - μ¤λ¥ μ‹ κΈ°λ³Έ λ¨λΈ `beomi/KoAlpaca-Polyglot-5.8B`λ΅ ν΄λ°±
  - `peft` λΌμ΄λΈλ¬λ¦¬ import μ κ±°

#### 2. `requirements.txt`
- **λ³€κ²½μ‚¬ν•­**:
  - `peft==0.15.2` λΌμ΄λΈλ¬λ¦¬ μ κ±° (λ” μ΄μƒ ν•„μ”ν•μ§€ μ•μ)
  - μ£Όμ„ μ—…λ°μ΄νΈ: "LoRA/PEFT" β†’ "λ¨λΈ κ°€μ†ν™”"

#### 3. `.env`
- **λ³€κ²½μ‚¬ν•­**:
  - `FINETUNING_MODEL_ID`: `ft:gpt-3.5-turbo-0125:tset::BX2RnWfq` β†’ `minjeongHuggingFace/koalpaca-bang_e9`

#### 4. `.env.example`
- **λ³€κ²½μ‚¬ν•­**:
  - `FINETUNING_MODEL_ID` μμ‹κ°’ μ—…λ°μ΄νΈ

### π€ μ‚¬μ©λ²•

#### κΈ°μ΅΄ μ„¤μΉλ ν™κ²½μ—μ„ μ—…λ°μ΄νΈ
```bash
# peft λΌμ΄λΈλ¬λ¦¬ μ κ±° (μ„ νƒμ‚¬ν•­)
pip uninstall peft

# μƒλ΅μ΄ requirements.txt μ„¤μΉ
pip install -r requirements.txt
```

#### μƒλ΅ μ„¤μΉν•λ” κ²½μ°
```bash
git clone <repository-url>
cd runpod_ai_backend
pip install -r requirements.txt
python main.py
```

### π”§ μ‘λ™ λ°©μ‹

1. **1μ°¨ μ‹λ„**: `minjeongHuggingFace/koalpaca-bang_e9` λ¨λΈ λ΅λ“
2. **μ‹¤ν¨ μ‹**: `beomi/KoAlpaca-Polyglot-5.8B` κΈ°λ³Έ λ¨λΈλ΅ ν΄λ°±
3. **μ™„μ „ μ‹¤ν¨ μ‹**: λ¨λΈ μ—†μ΄ μ‘λ™ (RAG μ„λΉ„μ¤λ§ μ‚¬μ©)

### β… μ¥μ 

- **κ°„λ‹¨ν• λ¨λΈ λ΅λ“**: LoRA μ–΄λ‘ν„° μ—†μ΄ μ™„μ „ νμΈνλ‹λ λ¨λΈ μ§μ ‘ μ‚¬μ©
- **μ•μ •μ„± ν–¥μƒ**: ν—κΉ…νμ΄μ¤μ—μ„ μ§μ ‘ λ΅λ“ν•μ—¬ λ²„μ „ κ΄€λ¦¬ μ©μ΄
- **ν΄λ°± μ‹μ¤ν…**: λ¨λΈ λ΅λ“ μ‹¤ν¨ μ‹ κΈ°λ³Έ λ¨λΈλ΅ μλ™ λ€μ²΄
- **μμ΅΄μ„± κ°μ†**: PEFT λΌμ΄λΈλ¬λ¦¬ μ κ±°λ΅ μ„¤μΉ λ³µμ΅λ„ κ°μ†

### π“‹ ν…μ¤νΈ λ°©λ²•

μ„λ²„ μ‹μ‘ ν›„ λ‹¤μ μ—”λ“ν¬μΈνΈλ΅ ν…μ¤νΈ:

```bash
# ν—¬μ¤μ²΄ν¬
curl http://localhost:8000/health

# νμΈνλ‹ λ¨λΈλ΅ λ£° μ„¤λ… ν…μ¤νΈ
curl -X POST http://localhost:8000/explain-rules \
  -H "Content-Type: application/json" \
  -d '{
    "game_name": "λ°© νƒμ¶",
    "question": "κ²μ„ μ‹μ‘μ€ μ–΄λ–»κ² ν•λ‚μ”?",
    "chat_type": "finetuning"
  }'
```

### π” λ΅κ·Έ ν™•μΈ μ‚¬ν•­

μ„λ²„ μ‹μ‘ μ‹ λ‹¤μκ³Ό κ°™μ€ λ΅κ·Έκ°€ λ‚νƒ€λ‚μ•Ό ν•©λ‹λ‹¤:

```
π“¥ νμΈνλ‹λ λ¨λΈ λ΅λ“ μ¤‘: minjeongHuggingFace/koalpaca-bang_e9
π“¥ Tokenizer λ΅λ“ μ¤‘...
β… νμΈνλ‹ λ¨λΈ λ΅λ“ μ™„λ£
```

μ‹¤ν¨ μ‹:
```
β λ¨λΈ λ΅λ“ μ‹¤ν¨: [μ¤λ¥ λ©”μ‹μ§€]
π”„ κΈ°λ³Έ λ¨λΈλ΅ λ€μ²΄ μ‹λ„...
π“¥ κΈ°λ³Έ λ¨λΈ λ΅λ“: beomi/KoAlpaca-Polyglot-5.8B
β… κΈ°λ³Έ λ¨λΈ λ΅λ“ μ™„λ£
```

### π¨ μ£Όμμ‚¬ν•­

- μ²« μ‹¤ν–‰ μ‹ ν—κΉ…νμ΄μ¤μ—μ„ λ¨λΈμ„ λ‹¤μ΄λ΅λ“ν•λ―€λ΅ μΈν„°λ„· μ—°κ²°κ³Ό μ¶©λ¶„ν• μ €μ¥κ³µκ°„μ΄ ν•„μ”ν•©λ‹λ‹¤
- GPU λ©”λ¨λ¦¬κ°€ λ¶€μ΅±ν• κ²½μ° `torch_dtype=torch.float16` λ° `device_map="auto"` μ„¤μ •μ΄ λ„μ›€μ΄ λ©λ‹λ‹¤
- λ¨λΈ ν¬κΈ°κ°€ ν° κ²½μ° λ΅λ”©μ— μ‹κ°„μ΄ κ±Έλ¦΄ μ μμµλ‹λ‹¤

---

**μ—…λ°μ΄νΈ μ™„λ£μΌ**: 2025λ…„ 6μ›” 7μΌ  
**μ—…λ°μ΄νΈ λ‹΄λ‹Ήμ**: AI Assistant  
**λ¨λΈ μ†μ μ**: minjeongHuggingFace
